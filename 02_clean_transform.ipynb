{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 02 - Clean and Transform\n",
    "\n",
    "This notebook will highlights the step to clean and transform data into\n",
    "matrices readied for model fitting.\n",
    "\n",
    "Three type of matrices will be created:\n",
    "1. Term document matrix - sparse\n",
    "2. Term frequency inverse document frequency\n",
    "\n",
    "Fortunately, there is no missing value in this case.\n",
    "\n",
    "#### Small dataset\n",
    "\n",
    "Extracting only 20000 articles with almost equal number of fake and\n",
    "reliable labels. While 20000 is small compared to our big dataset, the matrix created afterward is still massive.\n",
    "\n",
    "After some testing, starting from row 910000 gives a good mix of reliable\n",
    "and fake articles.\n",
    "\n",
    "Notes: A random guess of all fake news will give about 70% accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from words_clean_function import denoise_text, normalize\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from gensim import corpora, matutils, models\n",
    "from gensim.similarities.docsim import MatrixSimilarity\n",
    "\n",
    "from scipy.sparse import save_npz, load_npz"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# define data path\n",
    "data_path = 'D:\\\\PycharmProjects\\\\springboard\\\\data\\\\'\n",
    "\n",
    "# Skip to 910000 row for the good mix of fake and reliable news\n",
    "skiprows = 910000\n",
    "nrows = 20000\n",
    "\n",
    "# Read in sample data\n",
    "df = pd.read_csv(f'{data_path}news_clean_1.csv',\n",
    "                 skiprows=skiprows,\n",
    "                 index_col=False,\n",
    "                 nrows=nrows,\n",
    "                 names=['index', 'type', 'content'])\n",
    "\n",
    "# Dropping index columns\n",
    "df = df.drop('index', axis=1)\n",
    "df.type.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "fake        15600\nreliable     4400\nName: type, dtype: int64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statement on the Release of Prisoners with link to list\n",
      "\n",
      "(Before It's News)\n",
      "\n",
      "[For list of the terrorists being released in Hebrew:\n",
      "\n",
      "http://www.shabas.gov.il/NR/rdonlyres/B43A2078-2C20-449D-AFC3-FDB247722BAD/0/reshima1.pdf\n",
      "\n",
      "Shortened link:\n",
      "\n",
      "http://bit.ly/19XgFuS ]\n",
      "\n",
      "Statement on the Release of Prisoners\n",
      "\n",
      "(Communicated by the Prime Ministerâs Media Adviser)\n",
      "\n",
      "In wake of the Cabinet decision to resume the diplomatic negotiations\n",
      "\n",
      "between Israel and the Palestinians and authorize a team of ministers to\n",
      "\n",
      "deal with the release of prisoners during the negotiations, the ministerial\n",
      "\n",
      "committee convened this evening (Sunday, 11 August 2013). Defense Minister\n",
      "\n",
      "Moshe Yaalon chaired the discussion; Justice Minister Tzipi Livni and\n",
      "\n",
      "Science, Technology and Space Minister Yaakov Peri also participated, as did\n",
      "\n",
      "representatives of the Prison Service, the Justice Ministry, the IDF and\n",
      "\n",
      "other agencies.\n",
      "\n",
      "The committee approved the release of 26 prisoners. The list of prisoners\n",
      "\n",
      "will be published on the Prison Service website http://www.ips.gov.il later\n",
      "\n",
      "tonight after notice has been given to those bereaved families that asked to\n",
      "\n",
      "be informed in advance.\n",
      "\n",
      "The list includes 14 prisoners who will be transferred to Gaza and 12 from\n",
      "\n",
      "Judea and Samaria. Eight prisoners on the list were due to be released in\n",
      "\n",
      "the next three years and two in the next six months. The prisoner release\n",
      "\n",
      "will be carried out at least 48 hours after the list will have been\n",
      "\n",
      "published. It was emphasized in the aforesaid discussion that that if any of\n",
      "\n",
      "the released prisoners return to hostile activity against the State of\n",
      "\n",
      "Israel, they will be returned to continue serving their sentences.\n",
      "\n",
      "Source: http://www.imra.org.il/story.php3?id=61729\n"
     ]
    }
   ],
   "source": [
    "# Print first article to view\n",
    "print(df.content[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cleaning\n",
    "\n",
    "The goal here is to clean all the article and create a Term document\n",
    "sparse matrix. As with any NLP projects, the following functions will\n",
    "clean and tokenize the articles. Afterward, TDM will be created using\n",
    "gensim package.\n",
    "\n",
    "Notes: Customize cleaning functions are a good way to learn more about NLP.\n",
    "\n",
    "The steps are as followed:\n",
    "1. De-noise\n",
    "    - Remove brackets/links content\n",
    "    - Remove contractions\n",
    "2. Tokenize\n",
    "3. Normalize\n",
    "    - Remove non ASCII\n",
    "    - Remove stopwords\n",
    "    - Remove punctuation\n",
    "    - Lowercase all words\n",
    "\n",
    "All the functions above are included with definition in words_clean_function.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Using map to quickly clean and tokenize our data\n",
    "df.content = df.content.map(denoise_text)\n",
    "df.content = df.content.map(word_tokenize)\n",
    "df.content = df.content.map(normalize)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['statement', 'release', 'prisoners', 'link', 'list', 'news', 'statement', 'release', 'prisoners', 'communicated', 'prime', 'ministeras', 'media', 'adviser', 'wake', 'cabinet', 'decision', 'resume', 'diplomatic', 'negotiations', 'israel', 'palestinians', 'authorize', 'team', 'ministers', 'deal', 'release', 'prisoners', 'negotiations', 'ministerial', 'committee', 'convened', 'evening', 'sunday', '11', 'august', '2013', 'defense', 'minister', 'moshe', 'yaalon', 'chaired', 'discussion', 'justice', 'minister', 'tzipi', 'livni', 'science', 'technology', 'space', 'minister', 'yaakov', 'peri', 'also', 'participated', 'representatives', 'prison', 'service', 'justice', 'ministry', 'idf', 'agencies', 'committee', 'approved', 'release', '26', 'prisoners', 'list', 'prisoners', 'published', 'prison', 'service', 'website', 'later', 'tonight', 'notice', 'given', 'bereaved', 'families', 'asked', 'informed', 'advance', 'list', 'includes', '14', 'prisoners', 'transferred', 'gaza', '12', 'judea', 'samaria', 'eight', 'prisoners', 'list', 'due', 'released', 'next', 'three', 'years', 'two', 'next', 'six', 'months', 'prisoner', 'release', 'carried', 'least', '48', 'hours', 'list', 'published', 'emphasized', 'aforesaid', 'discussion', 'released', 'prisoners', 'return', 'hostile', 'activity', 'state', 'israel', 'returned', 'continue', 'serving', 'sentences', 'source']\n"
     ]
    }
   ],
   "source": [
    "# Print the first article again\n",
    "print(df.content[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sparse Term Document Matrix\n",
    "\n",
    "[Bag of Words](https://machinelearningmastery.com/gentle-introduction-bag-words-model/)\n",
    "\n",
    "[Term Document Matrix](https://en.wikipedia.org/wiki/Document-term_matrix)\n",
    "\n",
    "Gensim package provides a simple way to create sparse tdm with matutils.\n",
    "While tdm is a very straightforward representation of bag of words model,\n",
    "there will be a lot of zeros which increase our feature spaces tremendously!\n",
    "\n",
    "Steps to create TDM matrix:\n",
    "1. create lexicon (dictionary of all words)\n",
    "2. transform into matrix\n",
    "\n",
    "The dictionary created has 125557 unique tokens/words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(196679 unique tokens: ['11', '12', '14', '2013', '26']...)\n"
     ]
    }
   ],
   "source": [
    "# Create a word lexicon\n",
    "lexicon = corpora.Dictionary(df.content)\n",
    "print(lexicon)\n",
    "\n",
    "# bag of words\n",
    "bow = []\n",
    "for doc in df.content:\n",
    "    bow.append(lexicon.doc2bow(doc))\n",
    "\n",
    "# Create term frequency matrix\n",
    "tf_sparse_matrix = matutils.corpus2csc(bow)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csc.csc_matrix'>\n",
      "(196679, 20000)\n"
     ]
    }
   ],
   "source": [
    "# Print out first article again\n",
    "print(type(tf_sparse_matrix))\n",
    "print(tf_sparse_matrix.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since the matrix is inverted, it must be inverted back before saving\n",
    "to be fit later on.\n",
    "fake label = 0, reliable label = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (20000, 196679) and X type: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "y shape: (20000,) and y type: <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# Saving tf_sparse_matrix\n",
    "# A quick transformation of y into 0 for fake and 1 for reliable\n",
    "X = tf_sparse_matrix.T\n",
    "y = df.type.astype('category').cat.codes\n",
    "\n",
    "# Quick check before saving\n",
    "print(f'X shape: {X.shape} and X type: {type(X)}')\n",
    "print(f'y shape: {y.shape} and y type: {type(y)}')\n",
    "\n",
    "# Save to disk\n",
    "save_npz(f'{data_path}news_tf_sparse.npz', X)\n",
    "y.to_csv(f'{data_path}news_labels.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Term Frequency - Inverse Document Frequency\n",
    "\n",
    "[TF-IDF](http://www.tfidf.com/)\n",
    "\n",
    "TF-IDF weighing importance of words in the document and give it a score.\n",
    "A higher the score, the more importance is that word.\n",
    "\n",
    "Again, Gensim package provides intuitive way to create the matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.04208539, 0.        , 0.        , 0.        ],\n       [0.03988195, 0.        , 0.0580506 , 0.        ],\n       [0.04474735, 0.        , 0.        , 0.        ],\n       [0.04389755, 0.05998502, 0.02129851, 0.        ],\n       [0.05441932, 0.        , 0.02640354, 0.        ],\n       [0.06655783, 0.        , 0.        , 0.        ],\n       [0.05444635, 0.        , 0.        , 0.        ],\n       [0.05802789, 0.        , 0.        , 0.        ],\n       [0.06138134, 0.        , 0.        , 0.        ],\n       [0.1343428 , 0.        , 0.        , 0.        ],\n       [0.05370708, 0.        , 0.        , 0.        ],\n       [0.01518245, 0.        , 0.00736633, 0.        ],\n       [0.06234901, 0.        , 0.        , 0.        ],\n       [0.03910037, 0.        , 0.        , 0.        ],\n       [0.0479917 , 0.06557959, 0.06985483, 0.        ],\n       [0.0948211 , 0.        , 0.        , 0.        ],\n       [0.11451864, 0.        , 0.        , 0.        ],\n       [0.06860378, 0.        , 0.        , 0.        ],\n       [0.05433852, 0.        , 0.        , 0.        ],\n       [0.11083904, 0.        , 0.        , 0.        ],\n       [0.09695566, 0.        , 0.02352081, 0.        ],\n       [0.09302399, 0.        , 0.        , 0.        ],\n       [0.03529338, 0.        , 0.        , 0.        ],\n       [0.09921048, 0.        , 0.        , 0.        ],\n       [0.04007058, 0.        , 0.11665031, 0.        ],\n       [0.04337803, 0.        , 0.        , 0.        ],\n       [0.04154168, 0.        , 0.        , 0.        ],\n       [0.068066  , 0.        , 0.        , 0.        ],\n       [0.11238564, 0.        , 0.        , 0.        ],\n       [0.04018701, 0.        , 0.        , 0.        ],\n       [0.049617  , 0.        , 0.        , 0.        ],\n       [0.08332022, 0.        , 0.        , 0.        ],\n       [0.05833893, 0.        , 0.02830528, 0.        ],\n       [0.05239882, 0.        , 0.02542322, 0.        ],\n       [0.07818639, 0.        , 0.        , 0.        ],\n       [0.03544836, 0.        , 0.        , 0.        ],\n       [0.07170362, 0.        , 0.        , 0.        ],\n       [0.04368227, 0.        , 0.02119406, 0.        ],\n       [0.09871018, 0.        , 0.        , 0.        ],\n       [0.04811625, 0.        , 0.        , 0.        ]], dtype=float32)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize tf-idf model\n",
    "tf_idf = models.TfidfModel(bow)\n",
    "\n",
    "# tf-idf corpus\n",
    "tf_idf_corpus = []\n",
    "for doc in bow:\n",
    "    tf_idf_corpus.append(tf_idf[doc])\n",
    "\n",
    "# Create tf idf matrix\n",
    "tf_idf_matrix = matutils.corpus2dense(tf_idf_corpus, num_terms=len(lexicon.token2id))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the matrix for models. We also save tfidf corpus as this will be\n",
    "used for similarity matrix later on."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape is (20000, 196679)\n"
     ]
    }
   ],
   "source": [
    "# Save as X since y is unchanged\n",
    "X = tf_idf_matrix.T\n",
    "\n",
    "# Checking before save to disk\n",
    "print(f'X shape is {X.shape}')\n",
    "\n",
    "# Save to disk\n",
    "np.save(f'{data_path}news_tf_idf.npy', X)\n",
    "with open(f'{data_path}news_tf_idf_corpus.txt', 'wb') as fp:\n",
    "    pickle.dump(tf_idf_corpus, fp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}