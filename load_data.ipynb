{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Read in the data file\n",
    "\n",
    "Note that this is a very large data set with over 3.5 Gb. However, we will select\n",
    "only fake and reliable news from this data set to analyze.\n",
    "\n",
    "First we will work with a small chunk of data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "import re, string, unicodedata\n",
    "import contractions\n",
    "import inflect\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Data path for all saved data\n",
    "data_path = 'D:\\\\PycharmProjects\\\\springboard\\\\data\\\\'\n",
    "file_name = 'news_cleaned_2018_02_13.csv'\n",
    "\n",
    "# Chunk size\n",
    "nrow = 1000\n",
    "\n",
    "# Load data\n",
    "chunk = pd.read_csv(f'{data_path}{file_name}',\n",
    "                    nrows=nrow,\n",
    "                    encoding='ISO-8859-1',\n",
    "                    index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "    type                                            content  \\\n27  fake  Headline: Bitcoin & Blockchain Searches Exceed...   \n28  fake  Water Cooler 1/25/18 Open Thread; Fake News ? ...   \n29  fake  Veteran Commentator Calls Out the Growing âE...   \n30  fake  Lost Words, Hidden Words, Otters, Banks and Bo...   \n31  fake  Red Alert: Bond Yields Are SCREAMING âInflat...   \n\n                                                title  \\\n27  Surprise: Socialist Hotbed Of Venezuela Has Lo...   \n28  Water Cooler 1/25/18 Open Thread; Fake News ? ...   \n29  Veteran Commentator Calls Out the Growing âE...   \n30  Lost Words, Hidden Words, Otters, Banks and Books   \n31  Red Alert: Bond Yields Are SCREAMING âInflat...   \n\n                     authors  \n27         The Pirate'S Cove  \n28                       NaN  \n29                       NaN  \n30      Jackie Morris Artist  \n31  Phoenix Capital Research  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>content</th>\n      <th>title</th>\n      <th>authors</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>27</th>\n      <td>fake</td>\n      <td>Headline: Bitcoin &amp; Blockchain Searches Exceed...</td>\n      <td>Surprise: Socialist Hotbed Of Venezuela Has Lo...</td>\n      <td>The Pirate'S Cove</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>fake</td>\n      <td>Water Cooler 1/25/18 Open Thread; Fake News ? ...</td>\n      <td>Water Cooler 1/25/18 Open Thread; Fake News ? ...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>fake</td>\n      <td>Veteran Commentator Calls Out the Growing âE...</td>\n      <td>Veteran Commentator Calls Out the Growing âE...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>fake</td>\n      <td>Lost Words, Hidden Words, Otters, Banks and Bo...</td>\n      <td>Lost Words, Hidden Words, Otters, Banks and Books</td>\n      <td>Jackie Morris Artist</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>fake</td>\n      <td>Red Alert: Bond Yields Are SCREAMING âInflat...</td>\n      <td>Red Alert: Bond Yields Are SCREAMING âInflat...</td>\n      <td>Phoenix Capital Research</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retain these columns and rows only\n",
    "columns = ['type', 'content', 'title', 'authors']\n",
    "rows = ['fake', 'reliable']\n",
    "\n",
    "# Filter chunk to get df\n",
    "df = chunk[columns]\n",
    "df = df[df.type.isin(rows)]\n",
    "\n",
    "# Head of df\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "fake        124\nreliable     58\nName: type, dtype: int64"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.type.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pipeline\n",
    "\n",
    "Goal: Transform each Content columns and Title into a multiple vectors.\n",
    "\n",
    "Cleaning\n",
    "1. De-noise\n",
    "2. Tokens\n",
    "3. Stop words\n",
    "4. Lexicon Normalization - stemming and lemmatization\n",
    "\n",
    "Feature Engineering\n",
    "1. Bag of Words\n",
    "2. TF-IDF\n",
    "3. Word Embedding\n",
    "\n",
    "Further Improvement\n",
    "1. POS tagging\n",
    "2. Sentiment analysis\n",
    "3. Using vec2word somehow!\n",
    "\n",
    "Deep Learning\n",
    "1. Layers config\n",
    "2. loss config\n",
    "3. optimizer config\n",
    "\n",
    "Lets work with the very first fake new article in the df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cleaning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline: Bitcoin & Blockchain Searches Exceed Trump! Blockchain Stocks Are Next!\n",
      "\n",
      "Quite frankly, Iâm surprised it has half left. This is a country that cannot even produce toilet paper and beer. And theyâre stealing zoo animals for food. Here we have a Progressive/Marxist/Socialist station (CNN) telling us about how bad things are in a PMS nation\n",
      "\n",
      "Half the Venezuelan economy has disappeared\n",
      "\n",
      "Itâs getting worse. Unemployment will reach 30% and prices on all types of goods in the country will rise 13,000% this year, according to new figures published Thursday by the International Monetary Fund.\n",
      "\n",
      "The IMFâs economist for the Western Hemisphere, Alejandro Werner, put Venezuelaâs future bluntly.\n",
      "\n",
      "âIn Venezuela, the crisis continues,â Werner said in a blog post. He added that inflation is skyrocketing this year because of âthe loss of confidence in the nationâs currency.â\n",
      "\n",
      "This year will mark the third consecutive year of double-digit contractions in Venezuelaâs gross domestic product, the broadest measure of economic activity. The nationâs GDP declined 16% in 2016, 14% last year and itâs projected to fall 15% this year, according to the IMF.\n",
      "\n",
      "Venezuela is deep into an economic, political and humanitarian crisis, largely inflicted by the governmentâs own policies, economists say. Food and medical shortages are widespread. People are scavenging for food in dumpsters. Citizens are fleeing by the thousands. The currency, the bolivar, is nearly worthless. The government has defaulted on its debt. World leaders are calling President Nicolas Maduro a dictator.\n"
     ]
    }
   ],
   "source": [
    "# Get the article from content series\n",
    "article = df.content.iloc[0]\n",
    "\n",
    "# This article has multiple headings inside it.\n",
    "# Remove html links\n",
    "def remove_between_square_brackets(text):\n",
    "    \"\"\"Remove anything between brackets\"\"\"\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "# Remove http links\n",
    "def remove_links(text):\n",
    "    \"\"\"Remove http links in the text\"\"\"\n",
    "    return re.sub('(https\\S+|http\\S+)', '', text)\n",
    "\n",
    "# Replace contraction at this point will save us quite a bit of time later on\n",
    "def replace_contractions(text):\n",
    "    \"\"\"Replace contractions in string of text\"\"\"\n",
    "    return contractions.fix(text)\n",
    "\n",
    "# De-noise the text\n",
    "def denoise_text(text):\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_links(text)\n",
    "    text = replace_contractions(text)\n",
    "    return text\n",
    "\n",
    "article= denoise_text(article)\n",
    "print(article)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we tokenize and clean again\n",
    "\n",
    "### Tokenize"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "words = nltk.word_tokenize(article)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def replace_numbers(words):\n",
    "    \"\"\"Replace all integer occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "def normalize(words):\n",
    "    words = remove_non_ascii(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = replace_numbers(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words\n",
    "\n",
    "words = normalize(words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stemming and Lemmatize\n",
    "\n",
    "Is this necessary and how do we compare? Make 2 dataset and run through network?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "def stem_and_lemmatize(words):\n",
    "    stems = stem_words(words)\n",
    "    lemmas = lemmatize_verbs(words)\n",
    "    return stems, lemmas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "    type                                            content  \\\n27  fake  [headline, bitcoin, blockchain, searches, exce...   \n28  fake  [water, cooler, twelve thousand, five hundred ...   \n29  fake  [veteran, commentator, calls, growing, aethnon...   \n30  fake  [lost, words, hidden, words, otters, banks, bo...   \n31  fake  [red, alert, bond, yields, screaming, ainflati...   \n\n                                                title  \\\n27  Surprise: Socialist Hotbed Of Venezuela Has Lo...   \n28  Water Cooler 1/25/18 Open Thread; Fake News ? ...   \n29  Veteran Commentator Calls Out the Growing âE...   \n30  Lost Words, Hidden Words, Otters, Banks and Books   \n31  Red Alert: Bond Yields Are SCREAMING âInflat...   \n\n                     authors  \n27         The Pirate'S Cove  \n28                       NaN  \n29                       NaN  \n30      Jackie Morris Artist  \n31  Phoenix Capital Research  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>content</th>\n      <th>title</th>\n      <th>authors</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>27</th>\n      <td>fake</td>\n      <td>[headline, bitcoin, blockchain, searches, exce...</td>\n      <td>Surprise: Socialist Hotbed Of Venezuela Has Lo...</td>\n      <td>The Pirate'S Cove</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>fake</td>\n      <td>[water, cooler, twelve thousand, five hundred ...</td>\n      <td>Water Cooler 1/25/18 Open Thread; Fake News ? ...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>fake</td>\n      <td>[veteran, commentator, calls, growing, aethnon...</td>\n      <td>Veteran Commentator Calls Out the Growing âE...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>fake</td>\n      <td>[lost, words, hidden, words, otters, banks, bo...</td>\n      <td>Lost Words, Hidden Words, Otters, Banks and Books</td>\n      <td>Jackie Morris Artist</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>fake</td>\n      <td>[red, alert, bond, yields, screaming, ainflati...</td>\n      <td>Red Alert: Bond Yields Are SCREAMING âInflat...</td>\n      <td>Phoenix Capital Research</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean all columns and tokenize\n",
    "df.content = df.content.map(denoise_text)\n",
    "df.content = df.content.map(nltk.word_tokenize)\n",
    "df.content = df.content.map(normalize)\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}